# awesome-information-theoretic-representation-learning
A curated paper list for information-theoretic representation learning.

All papers are selected and sorted by topic/year/importance. Please send a pull request if you would like to add any paper.

## Papers

### Theories and Analysis
  - **Axiomatic derivation of the principle of maximum entropy and the principle of minimum cross-entropy** `IEEE Transactions on information theory, 1980`
   *JE Shore, RW Johnson* [[paper]](https://ieeexplore.ieee.org/abstract/document/1056144/)
  - **The principle of maximum entropy** `The mathematical intelligencer, 1985`
   *Silviu Guiasu, Abe Shenitzer* [[paper]](https://link.springer.com/article/10.1007/BF03023004)
  - **The role of entropy and reconstruction in multi-view self-supervised learning** `ICML, 2023`
   *Borja Rodrı́guez Gálvez, Arno Blaas, Pau Rodriguez, Adam Golinski, Xavier Suau, Jason Ramapuram, Dan Busbridge, Luca Zappella* [[paper]](https://proceedings.mlr.press/v202/rodri-guez-galvez23a.html)
  - **Self-Organization in a Perceptual Network** `Computer, 1988`
   *Ralph Linsker* [[paper]](https://ieeexplore.ieee.org/document/36)
  - **On Mutual Information Maximization for Representation Learning** `ICLR, 2020`
   *Michael Tschannen, Josip Djolonga, Paul K. Rubenstein, Sylvain Gelly, Mario Lucic* [[paper]](https://openreview.net/forum?id=rkxoh24FPH)
  - **Which Mutual-Information Representation Learning Objectives are Sufficient for Control?** `NeurIPS, 2021`
   *Kate Rakelly, Abhishek Gupta, Carlos Florensa, Sergey Levine* [[paper]](https://proceedings.neurips.cc/paper/2021/hash/dd45045f8c68db9f54e70c67048d32e8-Abstract.html)
  - **A Mutual Information Maximization Perspective of Language Representation Learning** `ICLR, 2020`
   *Lingpeng Kong, Cyprien de Masson d'Autume, Lei Yu, Wang Ling, Zihang Dai, Dani Yogatama* [[paper]](https://openreview.net/forum?id=Syx79eBKwr)

